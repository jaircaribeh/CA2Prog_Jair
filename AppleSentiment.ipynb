{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppleSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg9jWa858zZ99zs6ZDX0cb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaircaribeh/CA2Prog_Jair/blob/main/AppleSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhTYKua3l3xh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5065f5-dc81-4a18-f292-babd4bd2d3ff"
      },
      "source": [
        "!pip install umap-learn\n",
        "!pip install imblearn\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=7417dbd6b50c394f92eabb88cfdca1530a6dc447c9bd22fc232a6bf43cae5b05\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51362 sha256=48c31b618be2814b238c04bcaa8a2a4f1823c1c0b6905f6c1de49ba2dd59f32f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5SwyH_WmBjR"
      },
      "source": [
        "# importing the libraries\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm \n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPQHarnUmD7Z",
        "outputId": "305eecd8-7eba-4b66-eb4d-b02f3eccba43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwIsyvF2mrfK",
        "outputId": "a81f1228-94da-4c82-cca6-4c33408c5705"
      },
      "source": [
        "# reading the dataset \n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/bd/Apple_Sentiment.csv\", encoding=('ISO-8859-1'))\n",
        "print(dataset.head())\n",
        "print(dataset.shape)\n",
        "print(dataset.info())\n",
        "print(dataset.describe())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    _unit_id  ...                                               text\n",
            "0  623495513  ...  #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
            "1  623495514  ...  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
            "2  623495515  ...  My cat only chews @apple cords. Such an #Apple...\n",
            "3  623495516  ...  I agree with @jimcramer that the #IndividualIn...\n",
            "4  623495517  ...       Nobody expects the Spanish Inquisition #AAPL\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "(3886, 12)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3886 entries, 0 to 3885\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   _unit_id              3886 non-null   int64  \n",
            " 1   _golden               3886 non-null   bool   \n",
            " 2   _unit_state           3886 non-null   object \n",
            " 3   _trusted_judgments    3886 non-null   int64  \n",
            " 4   _last_judgment_at     3783 non-null   object \n",
            " 5   sentiment             3886 non-null   object \n",
            " 6   sentiment:confidence  3886 non-null   float64\n",
            " 7   date                  3886 non-null   object \n",
            " 8   id                    3886 non-null   float64\n",
            " 9   query                 3886 non-null   object \n",
            " 10  sentiment_gold        103 non-null    object \n",
            " 11  text                  3886 non-null   object \n",
            "dtypes: bool(1), float64(2), int64(2), object(7)\n",
            "memory usage: 337.9+ KB\n",
            "None\n",
            "           _unit_id  _trusted_judgments  sentiment:confidence            id\n",
            "count  3.886000e+03         3886.000000           3886.000000  3.886000e+03\n",
            "mean   6.234975e+08            3.687082              0.829526  5.410039e+17\n",
            "std    1.171906e+03            2.004595              0.175864  7.942752e+14\n",
            "min    6.234955e+08            3.000000              0.332700  5.400000e+17\n",
            "25%    6.234965e+08            3.000000              0.674475  5.400000e+17\n",
            "50%    6.234975e+08            3.000000              0.811250  5.410000e+17\n",
            "75%    6.234984e+08            3.000000              1.000000  5.420000e+17\n",
            "max    6.235173e+08           27.000000              1.000000  5.420000e+17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv3gvQw9Te50"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2QmxkjeT3qQ"
      },
      "source": [
        "# Checking if the sentiment. There is no balance between there setiment.\n",
        "dataset.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmm9PEDrdXdo"
      },
      "source": [
        "dataset._unit_state.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_LhdNpafBGj"
      },
      "source": [
        "# plot to see the sentiment \n",
        "%matplotlib inline \n",
        "dataset.sentiment.value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4yLszRUYGRJ"
      },
      "source": [
        "#Fazer o balanceamento depois\n",
        "#Balancing class \n",
        "sentiment = SMOTE()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNxyg1Tg7FlU"
      },
      "source": [
        "dataset.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZBeBkIp7xC_"
      },
      "source": [
        "#Cleaning the data \n",
        "# Remove double lines == it is done.\n",
        "# remove Stopwords\n",
        "# Stemming or Lemmatization \n",
        "# Remove things that we don't need as links, emojis... etc.\n",
        "\n",
        "\n",
        "dataset.drop_duplicates(['text'], inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As1BhCyN9OVq"
      },
      "source": [
        "dataset.text.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w_zJyjB91L0"
      },
      "source": [
        "# split tweet into two parts\n",
        "tweets = dataset['text']\n",
        "sentiment = dataset['sentiment']\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-l1mbs0_Vkk",
        "outputId": "e442fa20-dcf0-41ad-9dca-c439744cb500"
      },
      "source": [
        "# install library \n",
        "#Working with the NLTK library, using as a tool to work with texts\n",
        "\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRKwrav0_8SI"
      },
      "source": [
        "# Functions to prepare the data \n",
        "def remove_stopwords(tokens, portuguese, english):\n",
        "    \"\"\"\n",
        "    Takes a language (i.e. 'english'), and a set of word tokens.\n",
        "    Returns the tokenized text with any stopwords removed.\n",
        "    Stop words are words like \"is, the, a, ...\"\n",
        "    \"\"\"\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "    # Get the stopwords for the specified language\n",
        "    stop_words = stopwords.words(portuguese, english)\n",
        "\n",
        "    # Remove the stop words from the set of word tokens\n",
        "    tokens = set(tokens) - set(stop_words)\n",
        "\n",
        "    return tokens "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnh7lKfGERyd"
      },
      "source": [
        "def remove_stopwords_in_valid_word(valid_word_filename):\n",
        "    fp=open(NLP.stopwords_txt,'r',encoding='utf-8')\n",
        "    stopwords=fp.readlines()\n",
        "    fp.close()\n",
        "    fp=open(valid_word_filename,'r',encoding='utf-8')\n",
        "    valid_word=fp.readlines()\n",
        "    fp.close()\n",
        "    valid_word_new=[]\n",
        "    for word in valid_word:\n",
        "        if word in stopwords:\n",
        "            continue\n",
        "        else:\n",
        "            valid_word_new.append(word)\n",
        "    fp=open(valid_word_filename,'w',encoding='utf-8')\n",
        "    for word in valid_word_new:\n",
        "        fp.writelines(word)\n",
        "    fp.close() "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCKyZvIqElVS"
      },
      "source": [
        "#to reduce the vocabulary of sentences.\n",
        "def Stemming (instance):\n",
        "  stemmer =nltk.stem.RSLPStemmer()\n",
        "  word = []\n",
        "  for w in instance.split():\n",
        "    word.append(stemmer.stem(w))\n",
        "  return (instance)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr-cikqnMdH6"
      },
      "source": [
        "# remove links, comma, semicolon from the tweets\n",
        "def Cleaning_datas (instance):\n",
        "    instance = re.sub(r\"http\\S+\", \"\", instance).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('!','').replace('*','').replace('lol','')\n",
        "    return (instance)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66NooktUXFXr"
      },
      "source": [
        "# to remove articles as a as, the, o , or ... etc\n",
        "def RemoveStopWords(instancia):\n",
        "    stopwords = set(nltk.corpus.stopwords.words('portuguese','english'))\n",
        "    words = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(words))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNWQWwz1XlDf"
      },
      "source": [
        "# Lemmatization is similar to stemmer but when the word is reduced the \n",
        "#lemmatization make the word not lose its meaning = used only for english \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def Lemmatization (instance):\n",
        "  words = []\n",
        "  for w in instance.split():\n",
        "    words.append(wordnet_lemmatizer.lemmatize(w))\n",
        "    return (\" \".join(words))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mc-qrfdechR"
      },
      "source": [
        "## **understanding how the functions work**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GZgjHh7DeCyy",
        "outputId": "8fcde3fb-75c7-4618-f60a-07c2dd72dea6"
      },
      "source": [
        "\n",
        "RemoveStopWords('Eu nao gosto da Apple, eu nunca compraria um coisa desta marca')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Eu nao gosto Apple, nunca compraria coisa desta marca'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KZ1xuUENgG62",
        "outputId": "755d8d55-9b26-439f-ad7e-f6d40f448d0d"
      },
      "source": [
        "RemoveStopWords('I do not like the Apple, I will never buy things from this brand!')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I not like the Apple, I will never buy things from this brand!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K3OUbL0sgNlE",
        "outputId": "d26baa1e-6757-42e6-b38e-03aa4673299f"
      },
      "source": [
        "Stemming ('I dont like this brand, looks shit and it is a shit thing. i really hate it')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I dont like this brand, looks shit and it is a shit thing. i really hate it'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "q8llqHPp-G0d",
        "outputId": "d25f2195-f5fc-489d-e871-2222f3b74b6f"
      },
      "source": [
        "Cleaning_datas('http\\ : we need to buy more products from apple ** !!! it is amazing lol :)!!')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  we need to buy more products from apple   it is amazing  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mgLcnv-h_2mg",
        "outputId": "a4fda935-0907-4525-a219-3c96343491b2"
      },
      "source": [
        "Lemmatization('I dont like this brand, looks shit and it is a shit thing. i really hate it')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpXfaNsDgLkg"
      },
      "source": [
        "**applying** **the** **three** **data** **pre**-**processing** **functions** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNq4gN9-ATfy"
      },
      "source": [
        "def Preprocessing(instance):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    instance = re.sub(r\"http\\S+\", \"\", instance).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('$','').replace('*','').replace('#','').replace('@','')\n",
        "    stopwords = set(nltk.corpus.stopwords.words('portuguese','english'))\n",
        "    words = [stemmer.stem(i) for i in instance.split() if not i in stopwords]\n",
        "    return (\" \".join(words))\n",
        "\n",
        "# Applying all the functions to all the data:\n",
        "tweets = [Preprocessing(i) for i in tweets]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PzBZC5exCqPS",
        "outputId": "7ee46b8e-eb2b-4a5f-b9be-67eadd3c7d21"
      },
      "source": [
        "Preprocessing('http:\\ I do not like the Apple, I will never buy things from this brand! ')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i not lik the apple, i will nev buy thing from thil brand!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2QHCxoZnCO1j",
        "outputId": "402a24b4-e25d-48ca-ed32-7298ad78292e"
      },
      "source": [
        "Preprocessing('Eu não gosto do partido, e também não votaria novamente nesse governante. Assita o video aqui https:// :)')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gost partido, vot nov ness govern assit vide aqu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUJhcfnXDECx"
      },
      "source": [
        "**View** **tweets**\n",
        "\n",
        "note: fuction **stemmer** makes the words halved, often losing the meaning of the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzn8CiDwDBxR",
        "outputId": "25459d8a-1402-4ce3-edaf-3667b78e1a4e"
      },
      "source": [
        "tweets[:50]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
              "1     RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
              "2     My cat only chews @apple cords. Such an #Apple...\n",
              "3     I agree with @jimcramer that the #IndividualIn...\n",
              "4          Nobody expects the Spanish Inquisition #AAPL\n",
              "5     #AAPL:5 Rocket Stocks to Buy for December Gain...\n",
              "6     Top 3 all @Apple #tablets. Damn right! http://...\n",
              "7     CNBCTV: #Apple's margins better than expected?...\n",
              "8     Apple Inc. Flash Crash: What You Need to Know ...\n",
              "9     #AAPL:This Presentation Shows What Makes The W...\n",
              "10    WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...\n",
              "11    Apple Watch Tops Search Engine List of Best We...\n",
              "12    The Best-Designed #iPhone #Apps In the World, ...\n",
              "13    RT @peterpham: Bought my @AugustSmartLock at t...\n",
              "14    @apple Contact sync between Yosemite and iOS8 ...\n",
              "15    #aapl @applenws Thanks to the non factual dumb...\n",
              "16    WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...\n",
              "17    @Apple John Cantlie has been a prisoner of ISI...\n",
              "18    @apple- thanks for xtra checkin at upper wests...\n",
              "19    Why #AAPL Stock Had a Mini-Flash Crash Today: ...\n",
              "20    $AAPL dip only momentarily....just an aberrati...\n",
              "21    The JH Hines Staff with their newly issued @ap...\n",
              "22    @robconeybeer: You need an IP portfolio to def...\n",
              "23    @Apple, For the love of GAWD, CENTER the '1'on...\n",
              "24    i get the storage almost full notification lit...\n",
              "25    I had to do made the #switch from iPhone 6 to ...\n",
              "26    @ me RT @101Baemations: Can't stand those ppl ...\n",
              "27    Justice Department cites 18th century federal ...\n",
              "28    Latest Apple Products Leading in Efficiency ht...\n",
              "29    RT @thehill: Justice Department cites 18th cen...\n",
              "30    Good be huge RT @thehill Justice Department ci...\n",
              "31    @thehill @Apple i cite the 4th amendment as a ...\n",
              "33    RT @saxonidubom: @rwang0 @Apple Thanks...think...\n",
              "35    Way to stay relevant RT @thehill: Justice Depa...\n",
              "36    Apple Inc. Flash Crash: What You Need to Know ...\n",
              "37    http://t.co/hpC7p1rHvA\\nneed help on using you...\n",
              "39    That flash crash really screwed with a lot of ...\n",
              "40    RT @tra_hall: The JH Hines Staff with their ne...\n",
              "41                  Nigga update yall headphones @Apple\n",
              "44    Ok, @apple. You win. I won't use your browser ...\n",
              "46    @thehill @Apple I cite the us constitution whe...\n",
              "47    @apple U need to get ur fucking shit together ...\n",
              "48    @thehill @Apple Wish we could prosecute the ad...\n",
              "50    @thehill @Apple Furthermore there are no provi...\n",
              "51    #AAPL:Here's why Apple dropped...http://t.co/q...\n",
              "52    This one chart explains @tim_cook's affect on ...\n",
              "55    Final #AAPL #PutCallRatios for Monday, Decembe...\n",
              "56    #AAPL Launches Red #Apple Logo for World AIDS ...\n",
              "57                                  hey @apple fuck you\n",
              "58    5 Companies Growing Faster Than Apple Inc. htt...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ikKHIIIPvT"
      },
      "source": [
        "Tokenize\n",
        "Important function to use in twitter sentiment analysis as there are many new types of writing \n",
        "\n",
        "ex: =D  ,   :)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB2g9OTcHcvC"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxlC5luLJPT5"
      },
      "source": [
        "frase = 'Apply is very good! :D  #@blog'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR6mlFgTJ3NW",
        "outputId": "883c7eb1-dd72-47e7-b4bd-6c59d51a54b0"
      },
      "source": [
        "word_tokenize(frase)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apply', 'is', 'very', 'good', '!', ':', 'D', '#', '@', 'blog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtD5pC-ONIdU"
      },
      "source": [
        "## **This tokenizer is better for tweets**\n",
        "better because it understands the posts on twitter, you know what for example is an emoji, a happy or sad face\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSesLPCzL4jT"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlRxj2HMPA0"
      },
      "source": [
        "tweet_tokenizer = TweetTokenizer()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RiH6GD2MZ4M",
        "outputId": "bb81df3b-23cc-459d-c8ce-4f0b773f4c60"
      },
      "source": [
        "tweet_tokenizer.tokenize(frase)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apply', 'is', 'very', 'good', '!', ':D', '#', '@blog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeD4qe8cOL_4"
      },
      "source": [
        "### **creating a model**\n",
        "Creating a rating that will tell us the pattern, whether the tweet is positive or negative or neutral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdnUZ-S2NE-w",
        "outputId": "5935dd69-89ea-4f6c-e6b6-8e753629e2db"
      },
      "source": [
        "# Instantiates the object that vectorizes the text data\n",
        "vectorizer = CountVectorizer(analyzer=\"word\")\n",
        "# Applies vectorizer to text data\n",
        "freq_tweets = vectorizer.fit_transform(tweets)\n",
        "type(freq_tweets)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxDjOhzNxiM8",
        "outputId": "7d5026de-e879-4aa4-f881-35ca266cee01"
      },
      "source": [
        "#Training the model of machine learning\n",
        "model = MultinomialNB()\n",
        "model.fit(freq_tweets,sentiment)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8uEomxQMxEl",
        "outputId": "af6fde92-c18e-45da-c7ff-634b96166f5f"
      },
      "source": [
        "#Checking my matrix size \n",
        "freq_tweets.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3219, 8439)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tY4j4KBxUEs",
        "outputId": "81412e23-31bf-432c-8f82-bfe017f1a552"
      },
      "source": [
        "\n",
        "freq_tweets.A"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhyDvKnBzMPj"
      },
      "source": [
        "**Testing Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuwJcBjRzLdN"
      },
      "source": [
        "Test = ['@Maria my Apple is amazing',\n",
        "        'I did not like this new product :( sad, i would not spend my money on this!',\n",
        "        'new apple let see if it is ok',\n",
        "        'Im in love =D',\n",
        "        'thanks @apply']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFApL_PcyQDJ"
      },
      "source": [
        "Test = [Preprocessing(i) for i in Test]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfvCvzp3SKy"
      },
      "source": [
        "\n",
        "#Transforms test data into word vectors.\n",
        "freq_test = vectorizer.transform(Test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cExDnmEi3lhn",
        "outputId": "9dbfa645-c9fa-4a9c-daad-3e150b30fbee"
      },
      "source": [
        "#Ranking with the trained model.\n",
        "for t, c in zip (Test,model.predict(freq_test)):\n",
        "    print (t +\", \"+ c)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mar my appl is amazing, 5\n",
            "i did not lik thil new product ( sad, i would not spend my money on this!, 1\n",
            "new appl let see if it is ok, 1\n",
            "im in lov =d, 1\n",
            "thank apply, 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CULXxd574ZWY",
        "outputId": "3bcf6a74-ce35-49b1-d1b9-eafe0fd7ad2d"
      },
      "source": [
        "# probalility of each class\n",
        "print (modelo.classes_)\n",
        "modelo.predict_proba(freq_test).round(2)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '3' '5' 'not_relevant']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.61, 0.06, 0.33, 0.  ],\n",
              "       [1.  , 0.  , 0.  , 0.  ],\n",
              "       [0.87, 0.13, 0.  , 0.  ],\n",
              "       [0.73, 0.09, 0.18, 0.  ],\n",
              "       [0.51, 0.2 , 0.28, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq4omQ06mFMn"
      },
      "source": [
        "### **Fuction for Denial (Not or nao)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYZqvi1okFXO"
      },
      "source": [
        "def mark_denial(text):\n",
        "    denial = ['não','not','dont']\n",
        "    denial_detect = False\n",
        "    result = []\n",
        "    words = text.split()\n",
        "    for p in words:\n",
        "        p = p.lower()\n",
        "        if denial_detect == True:\n",
        "            p = p + '_NEG'\n",
        "        if p in denial:\n",
        "            denial_detect = True\n",
        "        result.append(p)\n",
        "    return (\" \".join(result))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LXpjUafKm6YR",
        "outputId": "b1f65185-6f2b-407e-aa81-5a8cf6c13503"
      },
      "source": [
        "# example \n",
        "mark_denial(' I like apply')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i like apply'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aOjggmRCnPQo",
        "outputId": "c3803a5e-4649-4253-e22b-cacd151258d8"
      },
      "source": [
        "mark_denial('I do not like apply')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i do not like_NEG apply_NEG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k98_zxyQnbrg",
        "outputId": "fab64e8f-b760-4799-f4d8-82dfd2630bc1"
      },
      "source": [
        "mark_denial ('i dont like apply')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i dont like_NEG apply_NEG'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MEZwoTWuGNy"
      },
      "source": [
        "### **Creating Models with Pipelines**\n",
        "\n",
        "Pipelines makes the code smaller\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZQqWRm_uTPg"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dwlNrPluYVw"
      },
      "source": [
        "# count vectorizer all my data, text\n",
        "# choosing the algorithm multinomial\n",
        "pipeline_simples = Pipeline([\n",
        "  ('counts', CountVectorizer()),\n",
        "  ('classifier', MultinomialNB())\n",
        "])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIYMT7Nvun5b"
      },
      "source": [
        "# using pipeline to identify (not, dont) in the tweets\n",
        "pipeline_denial = Pipeline([\n",
        "  ('counts', CountVectorizer(tokenizer=lambda text: mark_denial(text))),\n",
        "  ('classifier', MultinomialNB())\n",
        "])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHc11uHSu2kS",
        "outputId": "0568da53-e802-40f9-b2ca-6ca0965d3081"
      },
      "source": [
        "pipeline_simples.fit(tweets,sentiment)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('counts',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0KpBmXVu9AS",
        "outputId": "8c63804f-4dd8-4a15-e4c8-3f7dfee20ec7"
      },
      "source": [
        "pipeline_simples.steps"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('counts',\n",
              "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                  lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                  strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                  tokenizer=None, vocabulary=None)),\n",
              " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSu0XM2ivGnl",
        "outputId": "b1cd4d20-c7e5-4225-c770-b7776d2d0f8c"
      },
      "source": [
        "\n",
        "pipeline_denial.fit(tweets,sentiment)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('counts',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function <lambda> at 0x7fa74ddafb90>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx7TpICYvPgC",
        "outputId": "81d53358-ca10-4bb4-8ee8-1b58c1054351"
      },
      "source": [
        "\n",
        "pipeline_denial.steps"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('counts',\n",
              "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                  lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                  strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                  tokenizer=<function <lambda> at 0x7fa74ddafb90>,\n",
              "                  vocabulary=None)),\n",
              " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m71JtPHvcCb"
      },
      "source": [
        "### **Cross** **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQyMid2KvYZ3"
      },
      "source": [
        "\n",
        "result = cross_val_predict(pipeline_simples, tweets, sentiment, cv=10)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goZg5ctGvv_a",
        "outputId": "548afc37-2160-419c-ca6b-ea85d52e94b9"
      },
      "source": [
        "metrics.accuracy_score(sentiment,result)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6859273066169618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHqnvZ0Pv2lH",
        "outputId": "054cd9b9-69ca-464e-8ebe-5e30016de79d"
      },
      "source": [
        "sentimento=['1','3','5','no_relevant']\n",
        "print (metrics.classification_report(sentiment,result,sentimento))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.83      0.72      1092\n",
            "           3       0.73      0.76      0.75      1673\n",
            "           5       0.55      0.06      0.11       375\n",
            " no_relevant       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.69      0.70      0.69      3140\n",
            "   macro avg       0.48      0.41      0.40      3140\n",
            "weighted avg       0.68      0.70      0.66      3140\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0OBgbxWwdhV",
        "outputId": "9f8f7e04-344a-4524-eff2-bce597245e58"
      },
      "source": [
        "\n",
        "print (pd.crosstab(sentiment, result, rownames=['Real'], colnames=['Predito'], margins=True))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predito          1     3   5  not_relevant   All\n",
            "Real                                            \n",
            "1              905   185   2             0  1092\n",
            "3              374  1278  17             4  1673\n",
            "5              137   214  24             0   375\n",
            "not_relevant    10    67   1             1    79\n",
            "All           1426  1744  44             5  3219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVjO5Ijfw1I2"
      },
      "source": [
        "\n",
        "### **Evaluating model with Bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW_gimsew0Z7",
        "outputId": "bdd1ae36-3439-4306-a59e-162e772b07d3"
      },
      "source": [
        "'i like', 'like it'"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i like', 'like it')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF-07Lb2xUKk",
        "outputId": "29e316aa-c2b2-46d0-bb75-8a0c7f580b78"
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
        "freq_tweets = vectorizer.fit_transform(tweets)\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(freq_tweets,sentiment)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RtLGoSxbAG"
      },
      "source": [
        "result = cross_val_predict(model, freq_tweets, sentiment, cv=10)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj47ekl9xh6p",
        "outputId": "be944283-0937-4b95-fe30-471a49d51e40"
      },
      "source": [
        "metrics.accuracy_score(sentiment,result)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6756756756756757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqd4gGFOxrG7",
        "outputId": "862ba369-9886-4756-a5b6-927c929b0f07"
      },
      "source": [
        "sentimento=['1','3','5','no_relevant']\n",
        "print (metrics.classification_report(sentiment,result,sentimento))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.85      0.73      1092\n",
            "           3       0.76      0.70      0.73      1673\n",
            "           5       0.36      0.20      0.25       375\n",
            " no_relevant       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.68      0.69      0.68      3140\n",
            "   macro avg       0.44      0.44      0.43      3140\n",
            "weighted avg       0.67      0.69      0.67      3140\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA3_hijyyBCz",
        "outputId": "70ed56b5-7843-40c3-a17a-2e2060808a07"
      },
      "source": [
        "\n",
        "print (pd.crosstab(sentiment, result, rownames=['Real'], colnames=['Predito'], margins=True))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predito          1     3    5  not_relevant   All\n",
            "Real                                             \n",
            "1              925   149   18             0  1092\n",
            "3              387  1172  104            10  1673\n",
            "5              130   171   74             0   375\n",
            "not_relevant    13    50   12             4    79\n",
            "All           1455  1542  208            14  3219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2TqP0x3yQHg"
      },
      "source": [
        "## **Final considerations**\n",
        "Consider increasing the amount of training data.\n",
        "\n",
        "For its simplicity Naive Bayes can be used perfectly as a Baseline algorithm.\n",
        "\n",
        "Consider changing the algorithm parameters."
      ]
    }
  ]
}